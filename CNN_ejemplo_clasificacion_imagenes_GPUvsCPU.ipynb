{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación de imágenes con Redes Neuronales Convolucionales: Comparativa de tiempos de entrenamiento entre una GPU y CPU\n",
    "\n",
    "\n",
    "* El objetivo de este notebook es el mostrar cuantitativamente la diferencia de tiempos en entrenar un modelo de deep learning con una CPU y una GPU.\n",
    "\n",
    "* Para esta prueba vamos a disponer del siguiente Hardware:\n",
    "\n",
    "    + CPU: intel core i7 10750h / 2.6 ghz\n",
    "    + GPU: NVIDIA GeForce RTX 2060 8GB\n",
    "    \n",
    "* A continuación la implementación y ejecución:\n",
    "\n",
    "## 1.- Activamos uso GPU y limitamos uso uso de memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Usuario\\AppData\\Local\\Temp/ipykernel_7176/3391968063.py:9: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "# Limitación la memoria de la GPU\n",
    "config = tf.compat.v1.ConfigProto(allow_soft_placement=True)\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.6\n",
    "tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config))\n",
    "\n",
    "# Permitir crecimiento de la memoria\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    print('Invalid device or cannot modify virtual devices once initialized.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.- Obtenemos información de la GPU y la versión de TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### INFORMACIÓN ####\n",
      "  Versión de TensorFlow: 2.7.0\n",
      "  GPU: ['device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5']\n",
      "  Versión Cuda  -> 64_112\n",
      "  Versión Cudnn -> 64_8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('#### INFORMACIÓN ####')\n",
    "print('  Versión de TensorFlow: {}'.format(tensorflow.__version__))\n",
    "print('  GPU: {}'.format([x.physical_device_desc for x in device_lib.list_local_devices() if x.device_type == 'GPU']))\n",
    "print('  Versión Cuda  -> {}'.format(tensorflow.sysconfig.get_build_info()['cuda_version']))\n",
    "print('  Versión Cudnn -> {}\\n'.format(tensorflow.sysconfig.get_build_info()['cudnn_version']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.- Cargamos las imagenes de Entrenamiento y Test\n",
    "\n",
    "\n",
    "* El dataset de imágenes se ha obtenido de Kaggle: https://www.kaggle.com/alaanagy/8-kinds-of-image-classification\n",
    "\n",
    "\n",
    "* Para poder ejecutar este notebook se debe de descargar este dataset y guardarlo en la carpeta \"data\"\n",
    "\n",
    "* Este dataset contiene 3 carpetas (pred, test  y train) con 35.000 imagenes clasificadas en 8 clases diferentes: seas, streets, buildings, glaciers, mountains, forests, cats, and dogs.\n",
    "\n",
    "\n",
    "* Cada las carpetas test y train que son las que vamos a usar, contienen a su vez otras 8 carpetas; una por cada categoría, donde en cada una de esas carpetas estan las imágenes clasificadas por su categoría.\n",
    "\n",
    "\n",
    "* Para este experimento, vamos a crearnos dos objetos de la clase ***ImageDataGenerator*** (https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator), que dada una carpeta (en nuestro caso la carpeta train y test) generará tantas imágenes como le indiquemos para el entrenamiento (y test o validación) del modelo a entrenar.\n",
    "\n",
    "\n",
    "* Decimos tantas imágenes como le indiquemos ya que la clase ***ImageDataGenerator*** permite generar nuevas imágenes a partir de una dada haciendo ciertas modificaciones como rotaciones o zooms.\n",
    "\n",
    "\n",
    "* Para este experimento vamos a crear 2 datasets de imágenes:\n",
    "\n",
    "    + ***train_generator***: a partir de las carpeta de las imágenes de train, redimensionará las ***imágenes de tamaño 150x150 (PIXELES)*** y generará ***grupos de 32 imágenes (BATCH_SIZE)***, normalizadas y pudiendo realizar rotaciones (rotation_range) de 20 grados y zoom de hasta un 20% (zoom_range), pudiendo tambian modificar hasta un 20% de los píxeles de una foto (shear_range).\n",
    "    \n",
    "    + ***test_generator***: a partir de las carpeta de las imágenes de test, redimensionará las imágenes de tamaño 150x150 (PIXELES) y generará grupos de 32 imágenes (BATCH_SIZE), normalizadas. Dado que estas imágenes representan la \"realidad\", no realizaremos modificaciones de las mismas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18687 images belonging to 8 classes.\n",
      "Found 4463 images belonging to 8 classes.\n",
      "Nº de Imagenes para entrenamiento: 18687\n",
      "Nº de Imagenes para test: 4463\n",
      "Nº de Clases a Clasificar: 8 Clases\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "# CONSTANTES:\n",
    "PIXELES = 150                   # Pixeles del alto y ancho de la imagen p.e-> (150,150)\n",
    "BATCH_SIZE = 32                 # Número de imagenes por batch\n",
    "\n",
    "\n",
    "# Definimos como modificar de manera aleatoria las imagenes (pixeles) de entrenamiento\n",
    "train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   rotation_range=20,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "# Definimos como modificar las imagenes (pixeles) de test\n",
    "#   rescale = normalizamos los pixeles\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "# Definimos como son nuestras imagenes de entrenamiento y test\n",
    "train_generator = train_datagen.flow_from_directory(directory='./data/train',\n",
    "                                                    target_size=(PIXELES, PIXELES),\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(directory='./data/test',\n",
    "                                                  target_size=(PIXELES, PIXELES),\n",
    "                                                  batch_size=BATCH_SIZE,\n",
    "                                                  class_mode='categorical')\n",
    "\n",
    "num_classes = train_generator.num_classes\n",
    "print(\"Nº de Imagenes para entrenamiento: {}\".format(train_generator.n))\n",
    "print(\"Nº de Imagenes para test: {}\".format(test_generator.n))\n",
    "print(\"Nº de Clases a Clasificar: {} Clases\".format(num_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.- Definimos el modelo de la red neuronal convolucional\n",
    "\n",
    "* Definimos una red neuronal con la siguiente ***arquitectura***:\n",
    "\n",
    "    1. Imagenes de Entrada 150 pixeles Ancho, 150 Pixeles de Alto, 3 Canales\n",
    "    2. Capa Convolucional: 32 filtros, kernel (3x3), Función Activación RELU\n",
    "    3. MaxPooling: Reducción de (2,2)\n",
    "    4. Capa Convolucional: 64 filtros, kernel (3x3), Función Activación RELU\n",
    "    5. MaxPooling: Reducción de (2,2)\n",
    "    6. Capa Flatten: Capa de entrada del clasificador. Pasa cada Pixel a neurona\n",
    "    7. Capa Oculta 1: 512 Neurona, Función Activación RELU\n",
    "    8. Capa Oculta 2: 64 Neurona, Función Activación RELU\n",
    "    9. Capa Salida: 6 Neurona (6 Clases), Función Activación SOFTMAX\n",
    "    \n",
    "    \n",
    "* El modelo va a tener ***42 Millones de parámetros*** (exactamente 42.520.584 parámetros)\n",
    "\n",
    "\n",
    "* Para la ***optimización de los parámetros*** de la red utilizaremos:\n",
    "\n",
    "    + Función de perdida: ***categorical_crossentropy***\n",
    "    + Optimizador: ***ADAM***\n",
    "    + Métricas a monitorizar: Accuracy\n",
    "    \n",
    "    \n",
    "#### Nota: La finalidad de este proyecto no es la de conseguir el mejor modelo posible de clasificación de los 8 tipos de imágenes del dataset, si no la de mostrar las diferencias de tiempo de entrenamiento que hay entre el uso de una CPU y GPU. Por ese motivo se ha definido una red neuronal con un número de parámetros (42M) lo suficientemente relevante como para ver las diferencias de tiempos de entrenamiento entre una CPU y GPU. Seguramente con una red neuronal menos compleja (con menos parámetros) se conseguiran mejores resultados de accuracy en la clasificación de estas imágenes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 72, 72, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 36, 36, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 82944)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               42467840  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                32832     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 520       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,520,584\n",
      "Trainable params: 42,520,584\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "\n",
    "# Definimos el modelo\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32,\n",
    "                 kernel_size=(3, 3),\n",
    "                 input_shape=(PIXELES, PIXELES, 3),\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(filters=64,\n",
    "                 kernel_size=(3, 3),\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Imprimimos por pantalla la arquitectura de la red definida\n",
    "print(model.summary())\n",
    "\n",
    "# Compilamos el modelo\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.- Entrenamos la red con la GPU\n",
    "\n",
    "\n",
    "* Tanto para el entrenamiento del modelo con GPU y CPU usaremos:\n",
    "\n",
    "    + epochs: ***5 epochs***\n",
    "    + steps_per_epoch: Cada epoch tendrá ***1000 batches de 32 imágenes***\n",
    "    + imágenes de entrenamiento: imagenes cargadas en la variable ***train_generator*** de la clase ImageDataGenerator\n",
    "    + imágenes de test: tras cada epoch se validarán 320 imágenes (***10 batches*** *validation_steps* de ***32 imágenes***) cargadas en la variable *test_generator* de la clase ImageDataGenerator\n",
    "    + workers: número de hilos (*12*) para el procesamiento en paralelo de la CPU. Para el caso del entrenamiento con GPU, será la CPU la encargada de pasar a la GPU los batches con las imágenes de entrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### EJECUCIÓN CON GPU ###\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 40s 37ms/step - loss: 1.0500 - categorical_accuracy: 0.6237 - val_loss: 0.9117 - val_categorical_accuracy: 0.6656\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.7225 - categorical_accuracy: 0.7492 - val_loss: 0.7006 - val_categorical_accuracy: 0.7500\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 44s 43ms/step - loss: 0.6291 - categorical_accuracy: 0.7859 - val_loss: 0.6797 - val_categorical_accuracy: 0.7625\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 44s 43ms/step - loss: 0.5530 - categorical_accuracy: 0.8082 - val_loss: 0.7137 - val_categorical_accuracy: 0.7625\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.5133 - categorical_accuracy: 0.8259 - val_loss: 0.7788 - val_categorical_accuracy: 0.7125\n"
     ]
    }
   ],
   "source": [
    "# CONSTANTES:\n",
    "NUM_EPOCHS = 5                  # Número de epochs\n",
    "NUM_BATCHES_PER_EPOCH = 1000    # Número de Batches a realizar en cada EPOCH\n",
    "\n",
    "# Ejecución con GPU\n",
    "try:\n",
    "    with tensorflow.device('/gpu:0'):\n",
    "        print(\"### EJECUCIÓN CON GPU ###\")\n",
    "        model.fit(train_generator,\n",
    "                  epochs=NUM_EPOCHS,\n",
    "                  steps_per_epoch=NUM_BATCHES_PER_EPOCH,\n",
    "                  validation_data=test_generator,\n",
    "                  validation_steps=10,\n",
    "                  workers=12,\n",
    "                  verbose=1)\n",
    "except Exception as e:\n",
    "    print('WARNING: No es posible ejecutar con GPU: {}'.format(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.- Entrenamos la red con la CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### EJECUCIÓN CON CPU ###\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 408s 407ms/step - loss: 0.4876 - categorical_accuracy: 0.8331 - val_loss: 0.8306 - val_categorical_accuracy: 0.7437\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 418s 417ms/step - loss: 0.4548 - categorical_accuracy: 0.8434 - val_loss: 0.6814 - val_categorical_accuracy: 0.7688\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 413s 413ms/step - loss: 0.4243 - categorical_accuracy: 0.8528 - val_loss: 1.0471 - val_categorical_accuracy: 0.7375\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 416s 416ms/step - loss: 0.4104 - categorical_accuracy: 0.8592 - val_loss: 0.6739 - val_categorical_accuracy: 0.8062\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 419s 418ms/step - loss: 0.4008 - categorical_accuracy: 0.8615 - val_loss: 0.6210 - val_categorical_accuracy: 0.7750\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ejecución con CPU\n",
    "try:\n",
    "    with tensorflow.device('/cpu:0'):\n",
    "        print(\"### EJECUCIÓN CON CPU ###\")\n",
    "        model.fit(train_generator,\n",
    "                  epochs=NUM_EPOCHS,\n",
    "                  steps_per_epoch=NUM_BATCHES_PER_EPOCH,\n",
    "                  validation_data=test_generator,\n",
    "                  validation_steps=10,\n",
    "                  workers=12,\n",
    "                  verbose=1)\n",
    "except Exception as e:\n",
    "    print('WARNING: No es posible ejecutar con CPU: {}'.format(e))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (CNN_clasificacion_imagenes_GPUvsCPU)",
   "language": "python",
   "name": "pycharm-99007fa6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
